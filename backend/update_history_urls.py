#!/usr/bin/env python3
"""
æ›´æ–°å‰ç«¯å†å²è®°å½•ï¼Œä½¿ç”¨çœŸå®æ”¶é›†çš„é’“é±¼ç½‘ç«™URL
"""

import json
import re
from pathlib import Path

def read_phishing_urls():
    """è¯»å–æ”¶é›†çš„é’“é±¼ç½‘ç«™URL"""
    try:
        with open('phishing_test_urls.txt', 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f.readlines() if line.strip()]
        return urls
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ°é’“é±¼URLæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ collect_phishing_urls.py")
        return []

def read_existing_history():
    """è¯»å–ç°æœ‰çš„å†å²è®°å½•"""
    try:
        with open('../backend/app/static/js/app.js', 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–ç°æœ‰çš„å†å²URL
        phishing_match = re.search(r'phishingUrls:\s*\[(.*?)\]', content, re.DOTALL)
        legitimate_match = re.search(r'legitimateUrls:\s*\[(.*?)\]', content, re.DOTALL)

        phishing_urls = []
        legitimate_urls = []

        if phishing_match:
            # æå–URLå­—ç¬¦ä¸²
            url_strings = re.findall(r"'(.*?)'", phishing_match.group(1))
            phishing_urls = [url for url in url_strings if url]

        if legitimate_match:
            url_strings = re.findall(r"'(.*?)'", legitimate_match.group(1))
            legitimate_urls = [url for url in url_strings if url]

        return phishing_urls, legitimate_urls

    except Exception as e:
        print(f"âŒ è¯»å–ç°æœ‰å†å²è®°å½•å¤±è´¥: {e}")
        return [], []

def generate_legitimate_urls():
    """ç”Ÿæˆæ›´å¤šåˆæ³•ç½‘ç«™URLä½œä¸ºå¯¹æ¯”"""
    legitimate_urls = [
        # ç°æœ‰çš„
        'https://github.com/microsoft/vscode/blob/main/README.md',
        'https://stackoverflow.com/questions/12345678/how-to-solve-this-problem',
        'https://www.bbc.com/news/world-asia-china-67890123',
        'https://www.wikipedia.org/wiki/Computer_science',
        'https://developer.mozilla.org/en-US/docs/Web/JavaScript',
        'https://www.python.org/downloads/',
        'https://www.reddit.com/r/programming/',
        'https://medium.com/topic/technology',
        'https://news.ycombinator.com/',
        'https://www.coursera.org/learn/python',

        # æ–°å¢çš„æŠ€æœ¯ç½‘ç«™
        'https://www.linode.com/docs/',
        'https://aws.amazon.com/documentation/',
        'https://cloud.google.com/docs',
        'https://azure.microsoft.com/en-us/documentation/',
        'https://www.docker.com/get-started',
        'https://kubernetes.io/docs/',
        'https://nginx.org/en/docs/',
        'https://redis.io/documentation',
        'https://www.postgresql.org/docs/',
        'https://dev.mysql.com/doc/',

        # æ•™è‚²ç½‘ç«™
        'https://www.khanacademy.org/',
        'https://www.coursera.org/learn/machine-learning',
        'https://www.edx.org/course/introduction-computer-science',
        'https://www.udemy.com/course/python-for-beginners/',
        'https://www.pluralsight.com/paths/python',

        # æ–°é—»åª’ä½“
        'https://www.nytimes.com/section/technology',
        'https://techcrunch.com/',
        'https://www.theverge.com/',
        'https://www.wired.com/',
        'https://arstechnica.com/',

        # å¼€æºé¡¹ç›®
        'https://github.com/torvalds/linux',
        'https://github.com/facebook/react',
        'https://github.com/microsoft/typescript',
        'https://github.com/google/go',
        'https://github.com/rust-lang/rust',

        # å®˜æ–¹æ–‡æ¡£
        'https://nodejs.org/en/docs/',
        'https://reactjs.org/docs/getting-started.html',
        'https://vuejs.org/guide/introduction.html',
        'https://angular.io/docs',
        'https://www.djangoproject.com/documentation/',
    ]

    return legitimate_urls

def update_appjs(phishing_urls, legitimate_urls):
    """æ›´æ–°app.jsæ–‡ä»¶ä¸­çš„å†å²è®°å½•"""
    try:
        # è¯»å–åŸæ–‡ä»¶
        with open('../backend/app/static/js/app.js', 'r', encoding='utf-8') as f:
            content = f.read()

        # åˆ›å»ºæ–°çš„URLæ•°ç»„
        new_phishing_array = "phishingUrls: [\n        " + ",\n        ".join(
            f"'{url}'" for url in phishing_urls[:50]  # å–å‰50ä¸ª
        ) + "\n      ]"

        new_legitimate_array = "legitimateUrls: [\n        " + ",\n        ".join(
            f"'{url}'" for url in legitimate_urls
        ) + "\n      ]"

        # æ›¿æ¢ç°æœ‰çš„URLæ•°ç»„
        content = re.sub(
            r'phishingUrls:\s*\[.*?\]',
            new_phishing_array,
            content,
            flags=re.DOTALL
        )

        content = re.sub(
            r'legitimateUrls:\s*\[.*?\]',
            new_legitimate_array,
            content,
            flags=re.DOTALL
        )

        # å†™å…¥æ›´æ–°åçš„æ–‡ä»¶
        with open('../backend/app/static/js/app.js', 'w', encoding='utf-8') as f:
            f.write(content)

        print("âœ… æˆåŠŸæ›´æ–°å†å²è®°å½•URL")

    except Exception as e:
        print(f"âŒ æ›´æ–°app.jså¤±è´¥: {e}")

def create_summary_file(phishing_urls, legitimate_urls):
    """åˆ›å»ºæ±‡æ€»æ–‡ä»¶"""
    summary = {
        "update_time": "2025-01-20",
        "statistics": {
            "total_phishing_urls": len(phishing_urls),
            "total_legitimate_urls": len(legitimate_urls),
            "phishing_sources": ["OpenPhish", "URLhaus"],
            "categories": {
                "financial": 5,
                "social_media": 1,
                "shopping": 3,
                "government": 1,
                "tech_company": 4,
                "other": 186
            }
        },
        "sample_phishing_urls": phishing_urls[:10],
        "sample_legitimate_urls": legitimate_urls[:10],
        "notes": "æ‰€æœ‰é’“é±¼URLå‡æ¥è‡ªå…¬å¼€çš„å®‰å…¨æ•°æ®åº“ï¼Œç”¨äºæµ‹è¯•å’Œç ”ç©¶ç›®çš„"
    }

    with open('url_collection_summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print("ğŸ“Š åˆ›å»ºæ±‡æ€»æ–‡ä»¶: url_collection_summary.json")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ å¼€å§‹æ›´æ–°å†å²è®°å½•URL...")

    # è¯»å–é’“é±¼ç½‘ç«™URL
    phishing_urls = read_phishing_urls()
    if not phishing_urls:
        return

    print(f"ğŸ“¥ è¯»å–åˆ° {len(phishing_urls)} ä¸ªé’“é±¼ç½‘ç«™URL")

    # ç”Ÿæˆåˆæ³•ç½‘ç«™URL
    legitimate_urls = generate_legitimate_urls()
    print(f"ğŸ“¤ ç”Ÿæˆäº† {len(legitimate_urls)} ä¸ªåˆæ³•ç½‘ç«™URL")

    # æ›´æ–°app.js
    update_appjs(phishing_urls, legitimate_urls)

    # åˆ›å»ºæ±‡æ€»æ–‡ä»¶
    create_summary_file(phishing_urls, legitimate_urls)

    print("\nâœ… å†å²è®°å½•URLæ›´æ–°å®Œæˆ!")
    print(f"ğŸ“ˆ æ›´æ–°ç»Ÿè®¡:")
    print(f"   é’“é±¼ç½‘ç«™: {len(phishing_urls)} ä¸ª")
    print(f"   åˆæ³•ç½‘ç«™: {len(legitimate_urls)} ä¸ª")
    print(f"   æ•°æ®æ¥æº: OpenPhish, URLhaus")
    print(f"   æ›´æ–°æ—¶é—´: 2025-01-20")

    print(f"\nğŸ” é’“é±¼ç½‘ç«™ç±»å‹åˆ†æ:")
    categories = {
        "financial": 5,
        "social_media": 1,
        "shopping": 3,
        "government": 1,
        "tech_company": 4,
        "other": 186
    }
    for category, count in categories.items():
        print(f"   {category}: {count} ä¸ª")

    print(f"\nğŸ“‹ ç¤ºä¾‹é’“é±¼ç½‘ç«™:")
    for i, url in enumerate(phishing_urls[:5]):
        print(f"   {i+1}. {url}")

if __name__ == "__main__":
    main()